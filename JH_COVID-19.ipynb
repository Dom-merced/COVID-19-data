{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Novel Coronavirus COVID-19 (2019-nCoV) Unpivoted Data\n",
    "\n",
    "The following script takes data from the repository of the 2019 Novel Coronavirus Visual Dashboard operated by \n",
    "the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). It will apply necessary \n",
    "cleansing/reformatting to make it use in traditional relational databases and data visualization tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pygsheets\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pycountry\n",
    "from copy import deepcopy\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded directly from Johns Hopkins git repository, located at: https://github.com/CSSEGISandData/COVID-19. Their repository has three different CSV files for `confirmed`, `deaths` and `recovered` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\",keep_default_na=False)\n",
    "deaths = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv\",keep_default_na=False)\n",
    "recovered = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv\",keep_default_na=False)\n",
    "\n",
    "confirmed['Case_Type'] = 'Confirmed'\n",
    "deaths['Case_Type'] = 'Deaths'\n",
    "recovered['Case_Type'] = 'Recovered'\n",
    "\n",
    "key_columns = ['Country/Region','Province/State','Lat','Long','Case_Type']\n",
    "\n",
    "data = [confirmed, deaths, recovered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset stores the number of `Cases` for a given day in columns. \n",
    "This is not useful for reporting, thus we move these date columns to rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpivot(df):\n",
    "    # unpivot all non-key columns\n",
    "    melted = df.melt(id_vars=key_columns, var_name='Date', value_name = 'Cases')\n",
    "    # change our new Date field to Date type\n",
    "    melted['Date']= pd.to_datetime(melted['Date']) \n",
    "    \n",
    "    return melted\n",
    "\n",
    "unpivoted_data = list(map(unpivot, data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality \n",
    "\n",
    " 1. Replace empty values in cases to zero\n",
    " 2. Maitain consistent country naming (see: https://github.com/CSSEGISandData/COVID-19/issues/396)\n",
    " 3. After renaming countries, aggregate values values for one country/province per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_incorrect_county_state_data(df):\n",
    "    stateBeforeMarch9th = df[ (df['Date'] <= '2020-03-09') & (df['Country/Region'] == 'US') & (df['Province/State'].str.contains(',') == False) ].index\n",
    "    countryAfterMarch10th = df[ (df['Date'] > '2020-03-09') & (df['Country/Region'] == 'US') & df['Province/State'].str.contains(',') ].index\n",
    "\n",
    "    return df.drop(stateBeforeMarch9th).drop(countryAfterMarch10th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop incorrect county/state data\n",
    "\n",
    "unpivoted_data = [drop_incorrect_county_state_data(df) for df in unpivoted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdivisions = {i.name: i.code for i in pycountry.subdivisions.get(country_code=\"US\")}\n",
    "abbreviations = {subdivisions[k]: k for k in subdivisions}\n",
    "locality_replacements = {\"Washington, D.C.\": \"District of Columbia\"}\n",
    "\n",
    "def replace_localities(df):\n",
    "    return df.replace(locality_replacements)\n",
    "\n",
    "unpivoted_data = [replace_localities(df) for df in unpivoted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_US_geography(row):\n",
    "    county, state = row[\"Province/State\"].split(\", \")\n",
    "    state.replace(\"D.C.\", \"DC\")\n",
    "    row[\"Province/State\"] = abbreviations[\"US-\" + state.strip()]\n",
    "    return row\n",
    "        \n",
    "def resolve_geography_df(df):\n",
    "    return df.apply(lambda row: resolve_US_geography(row) if row['Country/Region'] == 'US' and row[\"Province/State\"] not in list(subdivisions.keys()) and \", \" in row[\"Province/State\"] else row, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivoted_data = [resolve_geography_df(df) for df in unpivoted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_names = {\n",
    "    \"Holy See\": \"Vatican City\",\n",
    "    \"Hong Kong SAR\": \"Hong Kong\",\n",
    "    \"Iran (Islamic Republic of)\": \"Iran\",\n",
    "    \"Macao SAR\": \"Macau\",\n",
    "    \"Republic of Korea\": \"South Korea\",\n",
    "    \"Republic of Moldova\": \"Moldova\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Saint Martin\": \"St. Martin\",\n",
    "    \"Taipei and environs\": \"Taiwan\",\n",
    "    \"Viet Nam\": \"Vietnam\",\n",
    "    \"occupied Palestinian territory\": \"Palestine\",\n",
    "}\n",
    "\n",
    "\n",
    "for idx,df in enumerate(unpivoted_data):\n",
    "    df[\"Country/Region\"] = df[\"Country/Region\"].replace(changed_names)\n",
    "    df[\"Cases\"] = df[\"Cases\"].replace('',0).astype(int)\n",
    "        \n",
    "    unpivoted_data[idx] = df.groupby(by=[\"Country/Region\",\"Province/State\",\"Date\",\"Case_Type\"], as_index=False) \\\n",
    "        .agg({\"Cases\": \"sum\", \"Long\": \"first\", \"Lat\": \"first\"})\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the data by primary keys and `Date`, to make sure we can add a `Differences` column easily. \n",
    "\n",
    "As `Cases` are actual snapshots (running numbers), to know what was the change since the previous day we introduce a new column called `Differences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = list( map(lambda df: df.sort_values(by=key_columns + ['Date'], ascending=True), unpivoted_data) )\n",
    "\n",
    "#sorted_data[0].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Difference` is today's `Cases` minus yesterday's `Cases` for each region/state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in sorted_data:\n",
    "    df[\"Difference\"] = df[\"Cases\"] - df.groupby( key_columns )[\"Cases\"].shift(1, fill_value = 0) \n",
    "\n",
    "concated = pd.concat(sorted_data)\n",
    "\n",
    "#concated.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-03-13 00:00:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concated = concated[concated['Date'] <= '2020-03-09' ]\n",
    "\n",
    "concated['Date'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to show the number of active cases. In our definition, `Active` is calculated as:\n",
    "\n",
    "```\n",
    "Active = Confirmed - Deaths - Recovered\n",
    "```\n",
    "\n",
    "As a first step, we merge the different type of cases into a single line for each `Country/Province/Date` keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = concated[concated[\"Case_Type\"].eq(\"Confirmed\")]\n",
    "deaths = concated[concated[\"Case_Type\"].eq(\"Deaths\")]\n",
    "recovered = concated[concated[\"Case_Type\"].eq(\"Recovered\")]\n",
    "\n",
    "active = confirmed  \\\n",
    "        .merge(deaths, validate= \"one_to_one\", suffixes =[\"\",\"_d\"], on=[\"Country/Region\",\"Province/State\",\"Date\"]) \\\n",
    "        .merge(recovered, validate= \"one_to_one\", suffixes =[\"\",\"_r\"], on= [\"Country/Region\",\"Province/State\",\"Date\"])\n",
    "\n",
    "#active.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apply the calculations both for `Cases` and `Difference`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "active[\"Case_Type\"] = 'Active'\n",
    "active[\"Cases\"] = active[\"Cases\"] - active[\"Cases_r\"] - active[\"Cases_d\"]\n",
    "active[\"Difference\"] = active[\"Difference\"] - active[\"Difference_r\"] - active[\"Difference_d\"]\n",
    "\n",
    "#active.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then merge the `Active` dataset with the original one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Confirmed', 'Deaths', 'Recovered', 'Active'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([concated,active], join=\"inner\")\n",
    "\n",
    "data[\"Case_Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we save the file locally, we add the `Last_Update_Date` in `UTC` time zone.\n",
    "\n",
    "### Writing local file: `JHU_COVID-19.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Last_Update_Date\"] = datetime.utcnow()\n",
    "data.to_csv(\"./JHU_COVID-19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload results to publicly available Google Sheets\n",
    "\n",
    "You have to have set service account credentials in `GSHEET_API_CREDENTIALS` environment variable. More information on how authententication works explained here: https://pygsheets.readthedocs.io/en/stable/authorization.html#environment-variables\n",
    "\n",
    "The public google sheet URL is: https://docs.google.com/spreadsheets/d/1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA/edit?ts=5e5e8a9e#gid=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GSHEET_API_CREDENTIALS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d61a93cbab69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#gsheet_key = '1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygsheets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account_env_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GSHEET_API_CREDENTIALS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsheet_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/COVID-19-data/venv/lib/python3.7/site-packages/pygsheets/authorization.py\u001b[0m in \u001b[0;36mauthorize\u001b[0;34m(client_secret, service_account_file, service_account_env_var, credentials_directory, scopes, custom_credentials, local, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_credentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mservice_account_env_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mservice_account_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mservice_account_env_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         credentials = service_account.Credentials.from_service_account_info(\n\u001b[1;32m    129\u001b[0m         service_account_info, scopes=scopes)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GSHEET_API_CREDENTIALS'"
     ]
    }
   ],
   "source": [
    "gsheet_key = os.environ.get('GSHEET_KEY', '1ZILeAru7cNH0FOUwFQllWh2MlVsdBKSc3LyBLmZsi9o')\n",
    "#gsheet_key = '1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA'\n",
    "\n",
    "gc = pygsheets.authorize(service_account_env_var='GSHEET_API_CREDENTIALS')\n",
    "\n",
    "sheet = gc.open_by_key(gsheet_key)[0]\n",
    "\n",
    "if sheet.rows < len(data.index):\n",
    "    sheet.add_rows(len(data.index) - sheet.rows)\n",
    "\n",
    "sheet.set_dataframe(data, 'A1')\n",
    "\n",
    "\"{} rows added to the worksheet\".format(sheet.rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to set up the AWS Access Key ID and AWS Secret Access Key to make it work\n",
    "# https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html\n",
    "BUCKET = 'test-covid19'# TODO update when we have the final s3 bucket\n",
    "FILE_NAME = 'JHU_COVID-19.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file(FILE_NAME, BUCKET, object_name=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
