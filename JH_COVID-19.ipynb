{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Novel Coronavirus COVID-19 (2019-nCoV) Unpivoted Data\n",
    "\n",
    "The following script takes data from the repository of the 2019 Novel Coronavirus Visual Dashboard operated by \n",
    "the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). It will apply necessary \n",
    "cleansing/reformatting to make it use in traditional relational databases and data visualization tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pygsheets\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pycountry\n",
    "from copy import deepcopy\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded directly from Johns Hopkins git repository, located at: https://github.com/CSSEGISandData/COVID-19. Their repository has three different CSV files for `confirmed`, `deaths` and `recovered` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\",keep_default_na=False)\n",
    "deaths = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv\",keep_default_na=False)\n",
    "recovered = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv\",keep_default_na=False)\n",
    "\n",
    "confirmed['Case_Type'] = 'Confirmed'\n",
    "deaths['Case_Type'] = 'Deaths'\n",
    "recovered['Case_Type'] = 'Recovered'\n",
    "\n",
    "key_columns = ['Country/Region','Province/State','Lat','Long','Case_Type']\n",
    "\n",
    "data = [confirmed, deaths, recovered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset stores the number of `Cases` for a given day in columns. \n",
    "This is not useful for reporting, thus we move these date columns to rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpivot(df):\n",
    "    # unpivot all non-key columns\n",
    "    melted = df.melt(id_vars=key_columns, var_name='Date', value_name = 'Cases')\n",
    "    # change our new Date field to Date type\n",
    "    melted['Date']= pd.to_datetime(melted['Date']) \n",
    "    \n",
    "    return melted\n",
    "\n",
    "unpivoted_data = list(map(unpivot, data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality \n",
    "\n",
    " 1. Replace empty values in cases to zero\n",
    " 2. Maitain consistent country naming (see: https://github.com/CSSEGISandData/COVID-19/issues/396)\n",
    " 3. After renaming countries, aggregate values values for one country/province per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_incorrect_county_state_data(df):\n",
    "    stateBeforeMarch9th = df[ (df['Date'] <= '2020-03-09') & (df['Country/Region'] == 'US') & (df['Province/State'].str.contains(',') == False) ].index\n",
    "    countryAfterMarch10th = df[ (df['Date'] > '2020-03-09') & (df['Country/Region'] == 'US') & df['Province/State'].str.contains(',') ].index\n",
    "\n",
    "    return df.drop(stateBeforeMarch9th).drop(countryAfterMarch10th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop incorrect county/state data\n",
    "\n",
    "unpivoted_data = [drop_incorrect_county_state_data(df) for df in unpivoted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdivisions = {i.name: i.code for i in pycountry.subdivisions.get(country_code=\"US\")}\n",
    "abbreviations = {subdivisions[k]: k for k in subdivisions}\n",
    "locality_replacements = {\"Washington, D.C.\": \"District of Columbia\"}\n",
    "\n",
    "def replace_localities(df):\n",
    "    return df.replace(locality_replacements)\n",
    "\n",
    "unpivoted_data = [replace_localities(df) for df in unpivoted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kitsap, WA', 'Solano, CA', 'Santa Cruz, CA', 'Napa, CA',\n",
       "       'Ventura, CA', 'Worcester, MA', 'Gwinnett, GA', 'DeKalb, GA',\n",
       "       'Floyd, GA', 'Fayette, GA', 'Gregg, TX', 'Monmouth, NJ',\n",
       "       'Burlington, NJ', 'Camden, NJ', 'Passaic, NJ', 'Union, NJ',\n",
       "       'Eagle, CO', 'Larimer, CO', 'Arapahoe, CO', 'Gunnison, CO',\n",
       "       'Kane, IL', 'Monroe, PA', 'Philadelphia, PA', 'Norfolk, VA',\n",
       "       'Arlington, VA', 'Spotsylvania, VA', 'Loudoun, VA',\n",
       "       \"Prince George's, MD\", 'Pottawattamie, IA', 'Camden, NC',\n",
       "       'Pima, AZ', 'Noble, IN', 'Adams, IN', 'Boone, IN', 'Dane, WI',\n",
       "       'Pierce, WI', 'Cuyahoga, OH', 'Weber, UT', 'Bennington County, VT',\n",
       "       'Carver County, MN', 'Charlotte County, FL', 'Cherokee County, GA',\n",
       "       'Collin County, TX', 'Jefferson County, KY',\n",
       "       'Jefferson Parish, LA', 'Shasta County, CA',\n",
       "       'Spartanburg County, SC', 'Harrison County, KY',\n",
       "       'Johnson County, IA', 'Berkshire County, MA',\n",
       "       'Davidson County, TN', 'Douglas County, OR', 'Fresno County, CA',\n",
       "       'Harford County, MD', 'Hendricks County, IN', 'Hudson County, NJ',\n",
       "       'Johnson County, KS', 'Kittitas County, WA', 'Manatee County, FL',\n",
       "       'Marion County, OR', 'Okaloosa County, FL', 'Polk County, GA',\n",
       "       'Riverside County, CA', 'Shelby County, TN',\n",
       "       'St. Louis County, MO', 'Suffolk County, NY', 'Ulster County, NY',\n",
       "       'Volusia County, FL', 'Fairfax County, VA',\n",
       "       'Rockingham County, NH', 'District of Columbia',\n",
       "       'Montgomery County, PA', 'Alameda County, CA',\n",
       "       'Broward County, FL', 'Lee County, FL', 'Pinal County, AZ',\n",
       "       'Rockland County, NY', 'Saratoga County, NY',\n",
       "       'Charleston County, SC', 'Clark County, WA', 'Cobb County, GA',\n",
       "       'Davis County, UT', 'El Paso County, CO', 'Honolulu County, HI',\n",
       "       'Jackson County, OR ', 'Jefferson County, WA',\n",
       "       'Kershaw County, SC', 'Klamath County, OR', 'Madera County, CA',\n",
       "       'Pierce County, WA', 'Tulsa County, OK', 'Douglas County, CO',\n",
       "       'Providence County, RI', 'Chatham County, NC',\n",
       "       'Delaware County, PA', 'Douglas County, NE', 'Fayette County, KY',\n",
       "       'Marion County, IN', 'Middlesex County, MA', 'Nassau County, NY',\n",
       "       'Ramsey County, MN', 'Washoe County, NV', 'Wayne County, PA',\n",
       "       'Yolo County, CA', 'Santa Clara County, CA', 'Clark County, NV',\n",
       "       'Fort Bend County, TX', 'Grant County, WA',\n",
       "       'Santa Rosa County, FL', 'Williamson County, TN',\n",
       "       'New York County, NY', 'Montgomery County, MD',\n",
       "       'Suffolk County, MA', 'Denver County, CO', 'Summit County, CO',\n",
       "       'Bergen County, NJ', 'Harris County, TX',\n",
       "       'San Francisco County, CA', 'Contra Costa County, CA',\n",
       "       'Orange County, CA', 'Norfolk County, MA', 'Maricopa County, AZ',\n",
       "       'Wake County, NC', 'Westchester County, NY', 'Grafton County, NH',\n",
       "       'Hillsborough, FL', 'Placer County, CA', 'San Mateo, CA',\n",
       "       'Sonoma County, CA', 'Umatilla, OR', 'Fulton County, GA',\n",
       "       'Washington County, OR', 'Snohomish County, WA',\n",
       "       'Humboldt County, CA', 'Sacramento County, CA',\n",
       "       'San Diego County, CA', 'San Benito, CA', 'Los Angeles, CA',\n",
       "       'King County, WA', 'Cook County, IL', 'Skagit, WA', 'Thurston, WA',\n",
       "       'Island, WA', 'Whatcom, WA', 'Marin, CA', 'Calaveras, CA',\n",
       "       'Stanislaus, CA', 'San Joaquin, CA', 'Essex, MA', 'Charlton, GA',\n",
       "       'Collier, FL', 'Pinellas, FL', 'Alachua, FL', 'Nassau, FL',\n",
       "       'Pasco, FL', 'Dallas, TX', 'Tarrant, TX', 'Montgomery, TX',\n",
       "       'Middlesex, NJ', 'Jefferson, CO', 'Multnomah, OR', 'Polk, OR',\n",
       "       'Deschutes, OR', 'McHenry, IL', 'Lake, IL', 'Bucks, PA',\n",
       "       'Hanover, VA', 'Lancaster, SC', 'Sullivan, TN', 'Johnson, IN',\n",
       "       'Howard, IN', 'St. Joseph, IN', 'Knox, NE', 'Stark, OH',\n",
       "       'Anoka, MN', 'Olmsted, MN', 'Summit, UT', 'Fairfield, CT',\n",
       "       'Litchfield, CT', 'Orleans, LA', 'Pennington, SD', 'Beadle, SD',\n",
       "       'Charles Mix, SD', 'Davison, SD', 'Minnehaha, SD', 'Bon Homme, SD',\n",
       "       'Socorro, NM', 'Bernalillo, NM', 'Oakland, MI', 'Wayne, MI',\n",
       "       'New Castle, DE', 'Washington', 'New York', 'California',\n",
       "       'Massachusetts', 'Diamond Princess', 'Grand Princess', 'Georgia',\n",
       "       'Colorado', 'Florida', 'New Jersey', 'Oregon', 'Texas', 'Illinois',\n",
       "       'Pennsylvania', 'Iowa', 'Maryland', 'North Carolina',\n",
       "       'South Carolina', 'Tennessee', 'Virginia', 'Arizona', 'Indiana',\n",
       "       'Kentucky', 'Nevada', 'New Hampshire', 'Minnesota', 'Nebraska',\n",
       "       'Ohio', 'Rhode Island', 'Wisconsin', 'Connecticut', 'Hawaii',\n",
       "       'Oklahoma', 'Utah', 'Kansas', 'Louisiana', 'Missouri', 'Vermont',\n",
       "       'Alaska', 'Arkansas', 'Delaware', 'Idaho', 'Maine', 'Michigan',\n",
       "       'Mississippi', 'Montana', 'New Mexico', 'North Dakota',\n",
       "       'South Dakota', 'West Virginia', 'Wyoming', 'Alabama'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpivoted_data[0][unpivoted_data[0][\"Country/Region\"] == \"US\"][\"Province/State\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_US_geography(row):\n",
    "    county, state = row[\"Province/State\"].split(\", \")\n",
    "    state.replace(\"D.C.\", \"DC\")\n",
    "    row[\"Province/State\"] = abbreviations[\"US-\" + state.strip()]\n",
    "    return row\n",
    "        \n",
    "def resolve_geography_df(df):\n",
    "    return df.apply(lambda row: resolve_US_geography(row) if row['Country/Region'] == 'US' and row[\"Province/State\"] not in list(subdivisions.keys()) and \", \" in row[\"Province/State\"] else row, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivoted_data = [resolve_geography_df(df) for df in unpivoted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_names = {\n",
    "    \"Holy See\": \"Vatican City\",\n",
    "    \"Hong Kong SAR\": \"Hong Kong\",\n",
    "    \"Iran (Islamic Republic of)\": \"Iran\",\n",
    "    \"Macao SAR\": \"Macau\",\n",
    "    \"Republic of Korea\": \"South Korea\",\n",
    "    \"Republic of Moldova\": \"Moldova\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Saint Martin\": \"St. Martin\",\n",
    "    \"Taipei and environs\": \"Taiwan\",\n",
    "    \"Viet Nam\": \"Vietnam\",\n",
    "    \"occupied Palestinian territory\": \"Palestine\",\n",
    "}\n",
    "\n",
    "\n",
    "for idx,df in enumerate(unpivoted_data):\n",
    "    df[\"Country/Region\"] = df[\"Country/Region\"].replace(changed_names)\n",
    "    df[\"Cases\"] = df[\"Cases\"].replace('',0).astype(int)\n",
    "        \n",
    "    unpivoted_data[idx] = df.groupby(by=[\"Country/Region\",\"Province/State\",\"Date\",\"Case_Type\"], as_index=False) \\\n",
    "        .agg({\"Cases\": \"sum\", \"Long\": \"first\", \"Lat\": \"first\"})\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the data by primary keys and `Date`, to make sure we can add a `Differences` column easily. \n",
    "\n",
    "As `Cases` are actual snapshots (running numbers), to know what was the change since the previous day we introduce a new column called `Differences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = list( map(lambda df: df.sort_values(by=key_columns + ['Date'], ascending=True), unpivoted_data) )\n",
    "\n",
    "#sorted_data[0].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Difference` is today's `Cases` minus yesterday's `Cases` for each region/state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in sorted_data:\n",
    "    df[\"Difference\"] = df[\"Cases\"] - df.groupby( key_columns )[\"Cases\"].shift(1, fill_value = 0) \n",
    "\n",
    "concated = pd.concat(sorted_data)\n",
    "\n",
    "#concated.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-03-13 00:00:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concated = concated[concated['Date'] <= '2020-03-09' ]\n",
    "\n",
    "concated['Date'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to show the number of active cases. In our definition, `Active` is calculated as:\n",
    "\n",
    "```\n",
    "Active = Confirmed - Deaths - Recovered\n",
    "```\n",
    "\n",
    "As a first step, we merge the different type of cases into a single line for each `Country/Province/Date` keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = concated[concated[\"Case_Type\"].eq(\"Confirmed\")]\n",
    "deaths = concated[concated[\"Case_Type\"].eq(\"Deaths\")]\n",
    "recovered = concated[concated[\"Case_Type\"].eq(\"Recovered\")]\n",
    "\n",
    "active = confirmed  \\\n",
    "        .merge(deaths, validate= \"one_to_one\", suffixes =[\"\",\"_d\"], on=[\"Country/Region\",\"Province/State\",\"Date\"]) \\\n",
    "        .merge(recovered, validate= \"one_to_one\", suffixes =[\"\",\"_r\"], on= [\"Country/Region\",\"Province/State\",\"Date\"])\n",
    "\n",
    "#active.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apply the calculations both for `Cases` and `Difference`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "active[\"Case_Type\"] = 'Active'\n",
    "active[\"Cases\"] = active[\"Cases\"] - active[\"Cases_r\"] - active[\"Cases_d\"]\n",
    "active[\"Difference\"] = active[\"Difference\"] - active[\"Difference_r\"] - active[\"Difference_d\"]\n",
    "\n",
    "#active.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then merge the `Active` dataset with the original one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Confirmed', 'Deaths', 'Recovered', 'Active'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([concated,active], join=\"inner\")\n",
    "\n",
    "data[\"Case_Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arizona', 'California', 'Colorado', 'Connecticut', 'Delaware',\n",
       "       'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Illinois',\n",
       "       'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maryland',\n",
       "       'Massachusetts', 'Michigan', 'Minnesota', 'Missouri', 'Nebraska',\n",
       "       'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "       'North Carolina', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
       "       'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n",
       "       'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'Wisconsin'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"Country/Region\"] == \"US\") & (data[\"Date\"] < \"2020-03-08\")][\"Province/State\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we save the file locally, we add the `Last_Update_Date` in `UTC` time zone.\n",
    "\n",
    "### Writing local file: `JHU_COVID-19.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Last_Update_Date\"] = datetime.utcnow()\n",
    "data.to_csv(\"./JHU_COVID-19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload results to publicly available Google Sheets\n",
    "\n",
    "You have to have set service account credentials in `GSHEET_API_CREDENTIALS` environment variable. More information on how authententication works explained here: https://pygsheets.readthedocs.io/en/stable/authorization.html#environment-variables\n",
    "\n",
    "The public google sheet URL is: https://docs.google.com/spreadsheets/d/1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA/edit?ts=5e5e8a9e#gid=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GSHEET_API_CREDENTIALS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d61a93cbab69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#gsheet_key = '1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygsheets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account_env_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GSHEET_API_CREDENTIALS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsheet_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/COVID-19-data/venv/lib/python3.7/site-packages/pygsheets/authorization.py\u001b[0m in \u001b[0;36mauthorize\u001b[0;34m(client_secret, service_account_file, service_account_env_var, credentials_directory, scopes, custom_credentials, local, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_credentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mservice_account_env_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mservice_account_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mservice_account_env_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         credentials = service_account.Credentials.from_service_account_info(\n\u001b[1;32m    129\u001b[0m         service_account_info, scopes=scopes)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GSHEET_API_CREDENTIALS'"
     ]
    }
   ],
   "source": [
    "gsheet_key = os.environ.get('GSHEET_KEY', '1ZILeAru7cNH0FOUwFQllWh2MlVsdBKSc3LyBLmZsi9o')\n",
    "#gsheet_key = '1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA'\n",
    "\n",
    "gc = pygsheets.authorize(service_account_env_var='GSHEET_API_CREDENTIALS')\n",
    "\n",
    "sheet = gc.open_by_key(gsheet_key)[0]\n",
    "\n",
    "if sheet.rows < len(data.index):\n",
    "    sheet.add_rows(len(data.index) - sheet.rows)\n",
    "\n",
    "sheet.set_dataframe(data, 'A1')\n",
    "\n",
    "\"{} rows added to the worksheet\".format(sheet.rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to set up the AWS Access Key ID and AWS Secret Access Key to make it work\n",
    "# https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html\n",
    "BUCKET = 'test-covid19'# TODO update when we have the final s3 bucket\n",
    "FILE_NAME = 'JHU_COVID-19.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file(FILE_NAME, BUCKET, object_name=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
