{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Novel Coronavirus COVID-19 (2019-nCoV) Unpivoted Data\n",
    "\n",
    "The following script takes data from the repository of the 2019 Novel Coronavirus Visual Dashboard operated by \n",
    "the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). It will apply necessary \n",
    "cleansing/reformatting to make it use in traditional relational databases and data visualization tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/csefalvayk/Developer/COVID-19-data/venv/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pygsheets\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pycountry\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded directly from Johns Hopkins git repository, located at: https://github.com/CSSEGISandData/COVID-19. Their repository has three different CSV files for `confirmed`, `deaths` and `recovered` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\",keep_default_na=False)\n",
    "deaths = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv\",keep_default_na=False)\n",
    "recovered = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv\",keep_default_na=False)\n",
    "\n",
    "confirmed['Case_Type'] = 'Confirmed'\n",
    "deaths['Case_Type'] = 'Deaths'\n",
    "recovered['Case_Type'] = 'Recovered'\n",
    "\n",
    "key_columns = ['Country/Region','Province/State','Lat','Long','Case_Type']\n",
    "\n",
    "data = [confirmed, deaths, recovered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset stores the number of `Cases` for a given day in columns. \n",
    "This is not useful for reporting, thus we move these date columns to rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpivot(df):\n",
    "    # unpivot all non-key columns\n",
    "    melted = df.melt(id_vars=key_columns, var_name='Date', value_name = 'Cases')\n",
    "    # change our new Date field to Date type\n",
    "    melted['Date']= pd.to_datetime(melted['Date']) \n",
    "    \n",
    "    return melted\n",
    "\n",
    "unpivoted_data = list(map(unpivot, data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality \n",
    "\n",
    " 1. Replace empty values in cases to zero\n",
    " 2. Maitain consistent country naming (see: https://github.com/CSSEGISandData/COVID-19/issues/396)\n",
    " 3. After renaming countries, aggregate values values for one country/province per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop incorrect county/state data\n",
    "\n",
    "for df in unpivoted_data:\n",
    "    stateBeforeMarch9th = df[ (df['Date'] <= '2020-03-09') & (df['Country/Region'] == 'US') & (df['Province/State'].str.contains(',') == False) ].index\n",
    "    countryAfterMarch10th = df[ (df['Date'] > '2020-03-09') & (df['Country/Region'] == 'US') & df['Province/State'].str.contains(',') ].index\n",
    "\n",
    "    df.drop(stateBeforeMarch9th & countryAfterMarch10th, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "subdivisions = {i.name: i.code for i in pycountry.subdivisions.get(country_code=\"US\")}\n",
    "abbreviations = {subdivisions[k]: k for k in subdivisions}\n",
    "\n",
    "\n",
    "locality_replacements = {\"Washington, D.C.\": \"District of Columbia\"}\n",
    "\n",
    "for df in unpivoted_data:\n",
    "    df.replace(locality_replacements, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def resolve_geography(df,row):\n",
    "    if row[1]['Country/Region'] == 'US' and row[1][\"Province/State\"] not in list(subdivisions.keys()):\n",
    "        if \", \" in row[1][\"Province/State\"]:\n",
    "            county, state = row[1][\"Province/State\"].split(\", \")\n",
    "            state.replace(\"D.C.\", \"DC\")\n",
    "            df.loc[row[0], \"Province/State\"] = abbreviations[\"US-\" + state.strip()]\n",
    "            \n",
    "for df in unpivoted_data:           \n",
    "    for row in df.iterrows():\n",
    "        resolve_geography(df, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Case_Type</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thailand</td>\n",
       "      <td></td>\n",
       "      <td>15.0000</td>\n",
       "      <td>101.0000</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan</td>\n",
       "      <td></td>\n",
       "      <td>36.0000</td>\n",
       "      <td>138.0000</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singapore</td>\n",
       "      <td></td>\n",
       "      <td>1.2833</td>\n",
       "      <td>103.8333</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nepal</td>\n",
       "      <td></td>\n",
       "      <td>28.1667</td>\n",
       "      <td>84.2500</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td></td>\n",
       "      <td>2.5000</td>\n",
       "      <td>112.5000</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20195</th>\n",
       "      <td>US</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>33.8837</td>\n",
       "      <td>-106.7235</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20196</th>\n",
       "      <td>US</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>35.0178</td>\n",
       "      <td>-106.6291</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20197</th>\n",
       "      <td>US</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>42.5922</td>\n",
       "      <td>-83.3362</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20198</th>\n",
       "      <td>US</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>42.2791</td>\n",
       "      <td>-83.3362</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20199</th>\n",
       "      <td>US</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>39.5393</td>\n",
       "      <td>-75.6674</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20200 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country/Region Province/State      Lat      Long  Case_Type       Date  \\\n",
       "0           Thailand                 15.0000  101.0000  Confirmed 2020-01-22   \n",
       "1              Japan                 36.0000  138.0000  Confirmed 2020-01-22   \n",
       "2          Singapore                  1.2833  103.8333  Confirmed 2020-01-22   \n",
       "3              Nepal                 28.1667   84.2500  Confirmed 2020-01-22   \n",
       "4           Malaysia                  2.5000  112.5000  Confirmed 2020-01-22   \n",
       "...              ...            ...      ...       ...        ...        ...   \n",
       "20195             US     New Mexico  33.8837 -106.7235  Confirmed 2020-03-11   \n",
       "20196             US     New Mexico  35.0178 -106.6291  Confirmed 2020-03-11   \n",
       "20197             US       Michigan  42.5922  -83.3362  Confirmed 2020-03-11   \n",
       "20198             US       Michigan  42.2791  -83.3362  Confirmed 2020-03-11   \n",
       "20199             US       Delaware  39.5393  -75.6674  Confirmed 2020-03-11   \n",
       "\n",
       "       Cases  \n",
       "0          2  \n",
       "1          2  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "20195      2  \n",
       "20196      1  \n",
       "20197      1  \n",
       "20198      1  \n",
       "20199      1  \n",
       "\n",
       "[20200 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpivoted_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_names = {\n",
    "    \"Holy See\": \"Vatican City\",\n",
    "    \"Hong Kong SAR\": \"Hong Kong\",\n",
    "    \"Iran (Islamic Republic of)\": \"Iran\",\n",
    "    \"Macao SAR\": \"Macau\",\n",
    "    \"Republic of Korea\": \"South Korea\",\n",
    "    \"Republic of Moldova\": \"Moldova\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Saint Martin\": \"St. Martin\",\n",
    "    \"Taipei and environs\": \"Taiwan\",\n",
    "    \"Viet Nam\": \"Vietnam\",\n",
    "    \"occupied Palestinian territory\": \"Palestine\",\n",
    "}\n",
    "\n",
    "\n",
    "for idx,df in enumerate(unpivoted_data):\n",
    "    df[\"Country/Region\"] = df[\"Country/Region\"].replace(changed_names)\n",
    "    df[\"Cases\"] = df[\"Cases\"].replace('',0).astype(int)\n",
    "        \n",
    "    unpivoted_data[idx] = df.groupby(by=[\"Country/Region\",\"Province/State\",\"Date\",\"Case_Type\"], as_index=False) \\\n",
    "        .agg({\"Cases\": \"sum\", \"Long\": \"first\", \"Lat\": \"first\"})\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the data by primary keys and `Date`, to make sure we can add a `Differences` column easily. \n",
    "\n",
    "As `Cases` are actual snapshots (running numbers), to know what was the change since the previous day we introduce a new column called `Differences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = list( map(lambda df: df.sort_values(by=key_columns + ['Date'], ascending=True), unpivoted_data) )\n",
    "\n",
    "#sorted_data[0].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Difference` is today's `Cases` minus yesterday's `Cases` for each region/state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in sorted_data:\n",
    "    df[\"Difference\"] = df[\"Cases\"] - df.groupby( key_columns )[\"Cases\"].shift(1, fill_value = 0) \n",
    "\n",
    "concated = pd.concat(sorted_data)\n",
    "\n",
    "#concated.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-03-11 00:00:00')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concated = concated[concated['Date'] <= '2020-03-09' ]\n",
    "\n",
    "concated['Date'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to show the number of active cases. In our definition, `Active` is calculated as:\n",
    "\n",
    "```\n",
    "Active = Confirmed - Deaths - Recovered\n",
    "```\n",
    "\n",
    "As a first step, we merge the different type of cases into a single line for each `Country/Province/Date` keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = concated[concated[\"Case_Type\"].eq(\"Confirmed\")]\n",
    "deaths = concated[concated[\"Case_Type\"].eq(\"Deaths\")]\n",
    "recovered = concated[concated[\"Case_Type\"].eq(\"Recovered\")]\n",
    "\n",
    "active = confirmed  \\\n",
    "        .merge(deaths, validate= \"one_to_one\", suffixes =[\"\",\"_d\"], on=[\"Country/Region\",\"Province/State\",\"Date\"]) \\\n",
    "        .merge(recovered, validate= \"one_to_one\", suffixes =[\"\",\"_r\"], on= [\"Country/Region\",\"Province/State\",\"Date\"])\n",
    "\n",
    "#active.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apply the calculations both for `Cases` and `Difference`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "active[\"Case_Type\"] = 'Active'\n",
    "active[\"Cases\"] = active[\"Cases\"] - active[\"Cases_r\"] - active[\"Cases_d\"]\n",
    "active[\"Difference\"] = active[\"Difference\"] - active[\"Difference_r\"] - active[\"Difference_d\"]\n",
    "\n",
    "#active.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then merge the `Active` dataset with the original one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Confirmed', 'Deaths', 'Recovered', 'Active'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([concated,active], join=\"inner\")\n",
    "\n",
    "data[\"Case_Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we save the file locally, we add the `Last_Update_Date` in `UTC` time zone.\n",
    "\n",
    "### Writing local file: `JHU_COVID-19.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Last_Update_Date\"] = datetime.utcnow()\n",
    "data.to_csv(\"./JHU_COVID-19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload results to publicly available Google Sheets\n",
    "\n",
    "You have to have set service account credentials in `GSHEET_API_CREDENTIALS` environment variable. More information on how authententication works explained here: https://pygsheets.readthedocs.io/en/stable/authorization.html#environment-variables\n",
    "\n",
    "The public google sheet URL is: https://docs.google.com/spreadsheets/d/1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA/edit?ts=5e5e8a9e#gid=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1ZILeAru7cNH0FOUwFQllWh2MlVsdBKSc3LyBLmZsi9o'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d89cc7eb8bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#gsheet_key = '1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygsheets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account_env_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgsheet_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/COVID-19-data/venv/lib/python3.7/site-packages/pygsheets/authorization.py\u001b[0m in \u001b[0;36mauthorize\u001b[0;34m(client_secret, service_account_file, service_account_env_var, credentials_directory, scopes, custom_credentials, local, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_credentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mservice_account_env_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mservice_account_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mservice_account_env_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         credentials = service_account.Credentials.from_service_account_info(\n\u001b[1;32m    129\u001b[0m         service_account_info, scopes=scopes)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1ZILeAru7cNH0FOUwFQllWh2MlVsdBKSc3LyBLmZsi9o'"
     ]
    }
   ],
   "source": [
    "gsheet_key = os.environ.get('GSHEET_KEY', '1ZILeAru7cNH0FOUwFQllWh2MlVsdBKSc3LyBLmZsi9o')\n",
    "#gsheet_key = '1avGWWl1J19O_Zm0NGTGy2E-fOG05i4ljRfjl87P7FiA'\n",
    "\n",
    "gc = pygsheets.authorize(service_account_env_var='GSHEET_API_CREDENTIALS')\n",
    "\n",
    "sheet = gc.open_by_key(gsheet_key)[0]\n",
    "\n",
    "if sheet.rows < len(data.index):\n",
    "    sheet.add_rows(len(data.index) - sheet.rows)\n",
    "\n",
    "sheet.set_dataframe(data, 'A1')\n",
    "\n",
    "\"{} rows added to the worksheet\".format(sheet.rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
